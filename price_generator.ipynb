{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d2d446f-18bb-4581-9fec-8b570852d009",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_date, lit, to_date, col, lag\n",
    "from pyspark.sql.window import Window\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 0: Create database\n",
    "# -----------------------------------------\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS inflation\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 1: Item Master Table\n",
    "# -----------------------------------------\n",
    "items = [\n",
    "    (1, \"Rice\", \"Food\", \"kg\"),\n",
    "    (2, \"Wheat Flour\", \"Food\", \"kg\"),\n",
    "    (3, \"Cooking Oil\", \"Food\", \"liter\"),\n",
    "    (4, \"Milk\", \"Food\", \"liter\"),\n",
    "    (5, \"Potato\", \"Vegetable\", \"kg\"),\n",
    "    (6, \"Onion\", \"Vegetable\", \"kg\"),\n",
    "    (7, \"Sugar\", \"Food\", \"kg\")\n",
    "]\n",
    "\n",
    "items_df = spark.createDataFrame(\n",
    "    items,\n",
    "    [\"item_id\", \"item_name\", \"category\", \"unit\"]\n",
    ")\n",
    "\n",
    "# Save as a table (optional, just to reference)\n",
    "items_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"inflation.item_master\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 2: Generate Mock Daily Prices\n",
    "# -----------------------------------------\n",
    "# Base prices\n",
    "base_prices = {\n",
    "    1: 65, 2: 55, 3: 180, 4: 90, 5: 40, 6: 60, 7: 85\n",
    "}\n",
    "\n",
    "# Function to generate random daily price fluctuation\n",
    "def generate_prices_for_date(run_date):\n",
    "    price_data = []\n",
    "    for item_id, base_price in base_prices.items():\n",
    "        # Random daily fluctuation +/- 2\n",
    "        daily_change = random.uniform(-2, 2)\n",
    "        price = round(base_price + daily_change, 2)\n",
    "        price_data.append((item_id, price))\n",
    "    \n",
    "    price_df = spark.createDataFrame(price_data, [\"item_id\", \"price\"])\n",
    "    \n",
    "    # Join with item master\n",
    "    daily_prices = (\n",
    "        items_df\n",
    "        .join(price_df, \"item_id\")\n",
    "        .withColumn(\"date\", to_date(lit(run_date)))\n",
    "        .withColumn(\"market\", lit(\"Kathmandu\"))\n",
    "        .withColumn(\"source\", lit(\"mock\"))\n",
    "    )\n",
    "    \n",
    "    return daily_prices\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 3: Backfill multiple days (optional)\n",
    "# -----------------------------------------\n",
    "# Number of past days to generate\n",
    "days_to_backfill = 30  # change to however many days you want\n",
    "all_days_data = []\n",
    "\n",
    "for i in range(days_to_backfill):\n",
    "    run_date = (datetime.today() - timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "    daily_df = generate_prices_for_date(run_date)\n",
    "    all_days_data.append(daily_df)\n",
    "\n",
    "# Combine all days into one DataFrame\n",
    "prices_df = all_days_data[0]\n",
    "for df in all_days_data[1:]:\n",
    "    prices_df = prices_df.union(df)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 4: Save as Delta Table\n",
    "# -----------------------------------------\n",
    "prices_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"inflation.daily_prices\")\n",
    "\n",
    "print(\"✅ Daily prices table generated and saved!\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 5: Calculate Daily Inflation %\n",
    "# -----------------------------------------\n",
    "window = Window.partitionBy(\"item_id\").orderBy(\"date\")\n",
    "\n",
    "inflation_df = (\n",
    "    spark.table(\"inflation.daily_prices\")\n",
    "    .withColumn(\"prev_price\", lag(\"price\").over(window))\n",
    "    .withColumn(\n",
    "        \"daily_inflation_pct\",\n",
    "        ((col(\"price\") - col(\"prev_price\")) / col(\"prev_price\")) * 100\n",
    "    )\n",
    ")\n",
    "\n",
    "inflation_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"inflation.daily_inflation\")\n",
    "\n",
    "print(\"✅ Daily inflation % table generated and saved!\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 6: Preview\n",
    "# -----------------------------------------\n",
    "display(spark.table(\"inflation.daily_prices\").orderBy(\"date\", \"item_id\"))\n",
    "display(spark.table(\"inflation.daily_inflation\").orderBy(\"date\", \"item_id\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "price_generator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
